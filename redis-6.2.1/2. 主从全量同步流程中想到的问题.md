# 全量同步流程中可能存在的问题

在学习 redis 同步机制的过程中发现一个理论上存在的问题，这里记录下。


## 1. Redis 全量同步流程

先说说 redis 的同步流程 (主要在 replication.c 和 rdb.c 中)：
    
1. slave 端主动发起同步请求，而后，主从进行握手协商 (我们这里假设协商后要进行全量同步)

2. master fork 自己 (fork的时候就相当于做了一份快照，但是由通过操作系统提供的 写时复制 来保证快照的性能)

    a. 被 fork 出来的子进程把数据 dump 到磁盘文件 RDB
    
    b. 而此时 主进程 依然会继续出来客户端的请求 （包括所有的增删改查）

    c. 再次期间所有新的数据变更都会暂存到主线程的 buffer 里边

3. 当 dump 完成了 master 通知 slave 下载 RDB 文件

4. slave 把 RDB 下载到本地，并且 load 到内存， 然后通知 master 处理完成

5. master 把 这期间的所有数据变更(在buffer)中都同步给slave，

6. 当slave 把增量数据也同步完成后，整个全量同步完成， master-slave 进入正常的实时同步状态


## 2. 存在的问题

其中的问题就在于全量传输中，增量数据的问题。试想一下下面这个场景(现实中不一定存在，但是理论上确实会发生)

1. master 开始dump文件时，仍然在对外提供服务，此时增量数据存储在 master 的 buffer 中

2. 假设 master 的磁盘访问及其缓慢，并且到 slave 下载 RDB 文件也及其缓慢

3. 与此同时， master 上有大规模的数据插入和更新 （这里需要注意的是， master上的 buffer 总归是有大小限制的）

4. 如果 master 上的 buffer 装不下所有的增量更新，那等到 slave 下载完成，那 master 上的 buffer 就相当于会有数据丢失了


## 2. 如何解决

上边的问题在网上找了半天，没有看到网友讨论，但是在 redislab 中 有相应的描述： [Endless Redis Replication Loop: What, Why and How to Solve It](https://redislabs.com/blog/the-endless-redis-replication-loop-what-why-and-how-to-solve-it/)

其解决办法，简单来说，就是通过限制 client 的访问频率，使得 buffer 不会溢出


问题来了，除了上述的办法，能否想到其他办法来处理:

1. 如果当 buffer 满了，溢出的时候，我们把 buffer 中的内容 dump 到磁盘文件中是否可能，算是一个单独的增量文件， 当全量文件传输完了我们在去传输增量文件

2. 把 增量 数据实时传输给 slave (这个可能需要重新开一个连接)
